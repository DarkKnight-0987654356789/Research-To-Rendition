# Research to Rendition

Research to Rendition is a repositry that aims to serve an essential purpose. 

The project serves to implement AI Research papers into practical implementations with well documented code. 

Be sure to star the repositry, newer implementations will be added frequently.

## Table of Contents


1)Formal Algorithms for Transformers(Phoung,Hutter)
The "Formal Algorithms for Transformers" paper explores mathematical foundations behind Transformer models in natural language processing (NLP). It details several self-attention mechanisms, positional encoding, and encoder-decoder architectures, detailing their theoretical aspects and computational efficiency. 

This paper serves as a good starting point for anyone who wants to understand the theoretical foundations of AI.

Link: https://arxiv.org/abs/2207.09238





